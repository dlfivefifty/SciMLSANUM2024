{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciML SANUM2024\n",
    "# Lab 2: Dual Numbers and ForwardDiff.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we explore a simple approach to computing derivatives:\n",
    "_dual numbers_. This is a special mathematical object akin to complex numbers\n",
    "that allows us to compute derivatives to very high accuracy in an automated fashion,\n",
    "and is an example of forward-mode [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).\n",
    "To realise dual numbers on a computer we need to introduce the notation of a \"type\"\n",
    "and create a customised type to represent dual numbers, which is what we discuss first.\n",
    "For functions of multiple variables we can extend the concept of dual numbers to computing gradients\n",
    "and Jacobians.\n",
    "After developing our own implementation of dual numbers we investigate using the more sophisticated version\n",
    "underlying ForwardDiff.jl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Outcomes**\n",
    "\n",
    "1. Definition and implementation of dual numbers and functions applied dual numbers.\n",
    "2. Using automatic differentiation to implement Newton's method.\n",
    "3. Extending dual numbers to gradients of 2D functions.\n",
    "3. Computing higher-dimensional gradients using ForwardDiff.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dual numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider implementing a type `Dual` to represent the dual number $a + bϵ$,\n",
    "in a way similar to `Complex` or `Rat`. For simplicity we don't restrict the types of `a` and `b`\n",
    "but for us they will usually be `Float64`. We create this type very similar to `Rat` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Dual\n",
    "    a\n",
    "    b\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily support addition of dual numbers as in `Rat` using the formula\n",
    "$$\n",
    "(a+bϵ) + (c+dϵ) = (a+c) + (b+d)ϵ\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual(4, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: + # we want to overload +\n",
    "\n",
    "function +(x::Dual, y::Dual)\n",
    "    a,b = x.a, x.b # x == a+bϵ. This gets out a and b\n",
    "    c,d = y.a, y.b # y == c+dϵ. This gets out c and d\n",
    "    Dual(a+c, b+d)\n",
    "end\n",
    "\n",
    "Dual(1,2) + Dual(3,4) # just adds each argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiplication we used the fact that $ϵ^2 = 0$ to derive the formula\n",
    "$$\n",
    "(a+bϵ)*(c+dϵ) = ac +(bc+ad)ϵ.\n",
    "$$\n",
    "Here we support this operation by overloading `*` when the inputs are both\n",
    "`Dual`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 262 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: * # we want to also overload *\n",
    "\n",
    "function *(x::Dual, y::Dual)\n",
    "    a,b = x.a, x.b # x == a+bϵ. This gets out a and b\n",
    "    c,d = y.a, y.b # y == c+dϵ. This gets out c and d\n",
    "    Dual(a*c, b*c + a*d)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiating polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual numbers allow us to differentiate functions provided they are composed of\n",
    "operations overloaded for `Dual`. In particular, the properties of multiplication imply that\n",
    "$$\n",
    "(a + b ϵ)^k = a^k + k b a^{k-1} ϵ\n",
    "$$\n",
    "and therefore by linearity if $f$ is a polynomial it must satisfy\n",
    "$$\n",
    "f(x + b ϵ) = f(x) + bf'(x)ϵ\n",
    "$$\n",
    "and thus if we set `b = 1` the \"dual part\" is equal to the derivative.\n",
    "We can use this fact to differentiate simple polynomials that only use `+`\n",
    "and `*`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual(10, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = x -> x*x*x + x\n",
    "f(Dual(2,1)) # (2^3 + 2) + (3*2^2+1)*ϵ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A polynomial like `x^3 + 1` is not yet supported.\n",
    "To support this we need to add addition of `Dual` with `Int` or `Float64`.\n",
    "Note that both of these are \"subtypes\" of `Real` and so restricting on `Real`\n",
    "will support both at the same time.\n",
    "We can overload the appropriate functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual(9, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: ^\n",
    "\n",
    "Dual(a::Real) = Dual(a, 0) # converts a real number to a dual number with no ϵ\n",
    "\n",
    "+(x::Real, y::Dual) = Dual(x) + y\n",
    "+(x::Dual, y::Real) = x + Dual(y)\n",
    "\n",
    "# a simple recursive function to support x^2, x^3, etc.\n",
    "function ^(x::Dual, n::Int)\n",
    "    if n < 0\n",
    "        error(\"Not implemented\") # don't support negative n, yet\n",
    "    end\n",
    "    if n == 1\n",
    "        x # Just return the input\n",
    "    else\n",
    "        ret = x\n",
    "        for k = 1:n-1\n",
    "            ret = ret*x\n",
    "        end\n",
    "        ret # returns the last argument\n",
    "    end\n",
    "end\n",
    "\n",
    "f = x -> x^3 + 1\n",
    "f(Dual(2,1))  # 2^3+1 + 3*2^2*ϵ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiating functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overload functions like `exp` so that they satisfy the rules of\n",
    "a _dual extension_, that is, are consistent with the formula $f(a+bϵ) = f(a) + bf'(a)ϵ$\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp (generic function with 15 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: exp\n",
    "exp(x::Dual) = Dual(exp(x.a), exp(x.a) * x.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to differentiate a function that composes these basic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual(41.193555674716116, 194.362805189629)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = x -> exp(x^2 + exp(x))\n",
    "f(Dual(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What makes dual numbers so effective is that, unlike other methods for approximating derivatives like divided differences, they are not\n",
    "prone to disasterous growth due to round-off errors: the above approximation\n",
    "matches the true answer to roughly 16 digits of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1(a)** Add support for `-`, `cos`, `sin`, and `/` to the type `Dual`\n",
    "by replacing the `# TODO`s in the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: -, cos, sin, /\n",
    "\n",
    "# The following supports negation -(a+bϵ)\n",
    "-(x::Dual) = Dual(-x.a, -x.b)\n",
    "\n",
    "# TODO: implement -(::Dual, ::Dual)\n",
    "# SOLUTION\n",
    "-(x::Dual, y::Dual) = Dual(x.a - y.a, x.b - y.b)\n",
    "# END\n",
    "\n",
    "\n",
    "function cos(x::Dual)\n",
    "    # TODO: implement cos for Duals\n",
    "    # SOLUTION\n",
    "    Dual(cos(x.a), -sin(x.a) * x.b)\n",
    "    # END\n",
    "end\n",
    "\n",
    "function sin(x::Dual)\n",
    "    # TODO: implement sin for Duals\n",
    "    # SOLUTION\n",
    "    Dual(sin(x.a), cos(x.a) * x.b)\n",
    "    # END\n",
    "end\n",
    "\n",
    "function /(x::Dual, y::Dual)\n",
    "    # TODO: implement division for Duals.\n",
    "    # Hint: think of this as x * (1/y)\n",
    "    # SOLUTION\n",
    "    if iszero(y.a)\n",
    "        error(\"Division for dual numbers is ill-defined when denonimator real part is zero.\")\n",
    "    end\n",
    "    return Dual(x.a / y.a, (y.a * x.b - x.a * y.b) / y.a^2)\n",
    "    # END\n",
    "end\n",
    "\n",
    "x = 0.1\n",
    "ϵ = Dual(0,1)\n",
    "@test cos(sin(x+ϵ)/(x+ϵ)).b ≈ -((cos(x)/x - sin(x)/x^2)sin(sin(x)/x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1(b)** Use dual numbers to compute the derivatives to\n",
    "1. $\\exp(\\exp x \\cos x + \\sin x)$\n",
    "2. $∏_{k=1}^{1000} \\left({x \\over k}-1\\right)$\n",
    "3. $f^{\\rm s}_{1000}(x)$ where $f^{\\rm s}_n(x)$ corresponds to $n$-terms of the following continued fraction:\n",
    "$$\n",
    "1 + {x-1 \\over 2 + {x-1 \\over 2 + {x-1 \\over 2 + ⋱}}}.\n",
    "$$\n",
    "at the point $x = 0.1$. Compare with divided differences to give evidence that your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5847725546108276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use dual numbers to compute the derivatives of the 3 functions above.\n",
    "# SOLUTION\n",
    "\n",
    "# Define the functions\n",
    "f = x -> exp(exp(x)cos(x) + sin(x))\n",
    "/(x::Dual, k::Int) = Dual(x.a/k, x.b/k) # missing overload from above\n",
    "-(x::Dual, k::Int) = Dual(x.a-k, x.b) # missing overload from above\n",
    "*(k::Int, x::Dual) = Dual(k*x.a, k*x.b) # missing overload from above\n",
    "g = function(x)\n",
    "    ret = 1\n",
    "    for k = 1:1000\n",
    "        ret *= x/k - 1\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "function cont(n, x)\n",
    "    ret = 2\n",
    "    for k = 1:n-1\n",
    "        ret = 2 + (x-1)/ret\n",
    "    end\n",
    "    1 + (x-1)/ret\n",
    "end\n",
    "\n",
    "# With the previous problems solved, this is as simple as running\n",
    "\n",
    "fdual = f(0.1+ϵ)\n",
    "fdual.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.593826513101571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdual = g(0.1+ϵ)\n",
    "gdual.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5811388300841893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contdual = cont(1000,0.1+ϵ)\n",
    "contdual.b\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2** Consider a simple forward Euler method approximating the solution to the Pendulum equation with friction:\n",
    "$$\n",
    "u'' = τ u' - \\sin u\n",
    "$$\n",
    "which we can rewrite as a first order system:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "   u' \\\\\n",
    "   v'\n",
    "   \\end{bmatrix} = \\begin{bmatrix} v \\\\ -τ*v - \\sin u \\end{bmatrix}\n",
    "$$\n",
    "That is, we want to implement the iteration\n",
    "$$\n",
    "𝐮_{k+1} = 𝐮_k + h*\\begin{bmatrix} 𝐮_k[2] \\\\ -τ 𝐮_k[2] - \\sin 𝐮_k[1] \\end{bmatrix}\n",
    "$$\n",
    "with a specified initial condition $𝐮_0$. For $N = 100$, $h = 0.1$ and $𝐮_0 = [0.1,0.2]$, differentiate\n",
    "the solution with-respect to $τ$ at $τ = 1$ using dual numbers.\n",
    "Hint: check your result by comparing to a divided difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Differentiate through an ODE solve using dual nubmers\n",
    "# SOLUTION\n",
    "𝐟 = function(h, 𝐱)\n",
    "    (τ,u,v) = 𝐱\n",
    "    [τ,u + h*v, v + h*(-τ*v - sin(u))]\n",
    "end\n",
    "\n",
    "function forwardeuler(τ, 𝐮₀, 𝐟, h, n)\n",
    "    𝐱 = [τ; 𝐮₀]\n",
    "    for k = 1:n\n",
    "        𝐱 = 𝐟(h, 𝐱)\n",
    "    end\n",
    "    𝐱[2]\n",
    "end\n",
    "\n",
    "\n",
    "## we need a few more overloads:\n",
    "*(x::Dual, y::Number) = x * Dual(y)\n",
    "*(x::Number, y::Dual) = Dual(x) * y\n",
    "-(x::Dual, y::Number) = x - Dual(y)\n",
    "\n",
    "\n",
    "der = forwardeuler(Dual(1.0,1.0),[0.1,0.2], 𝐟, 0.1, 100).b\n",
    "h = sqrt(eps())\n",
    "divd = (forwardeuler(1+h,[0.1,0.2], 𝐟, 0.1, 100)-forwardeuler(1,[0.1,0.2], 𝐟, 0.1, 100))/h\n",
    "@test der ≈ divd atol=1E-8\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual numbers extend naturally to higher dimensions by adding a different dual-part for each direction.\n",
    "We will consider a 2D version of a dual number:\n",
    "$$\n",
    "a + b ϵ_x + c ϵ_y\n",
    "$$\n",
    "such that\n",
    "$$\n",
    "ϵ_x^2 = ϵ_y^2 = ϵ_x ϵ_y =  0.\n",
    "$$\n",
    "Multiplication then follows the rule:\n",
    "$$\n",
    "(a + b ϵ_x + c ϵ_y) (α + β ϵ_x + γ ϵ_y) = aα + (bα + a β)ϵ_x + (cα + a γ)ϵ_y\n",
    "$$\n",
    "From this we see\n",
    "$$\n",
    "\\begin{align*}\n",
    " (a + b ϵ_x + c ϵ_y)^k (α + β ϵ_x + γ ϵ_y)^j &= (a^k + k b a^{k-1} ϵ_x + k c a^{k-1} ϵ_y)(α^j + j β α^{j-1} ϵ_x + j γ α^{j-1} ϵ_y) \\\\\n",
    "   &= a^k α^j + (jβ  a^k α^{j-1} + k b a^{k-1} α^j )ϵ_x + (jγ  a^k α^{j-1} + k c a^{k-1} α^j )ϵ_y\n",
    "\\end{align*}\n",
    "$$\n",
    "In particular, we have:\n",
    "$$\n",
    "(x + ϵ_x)^k (y + ϵ_y)^j = x^k y^j + k x^{k-1} y^j ϵ_x + j x^k y^{j-1} ϵ_y\n",
    "$$\n",
    "and hence by linearity if $f$ is a polynomial we can compute the gradient via:\n",
    "$$\n",
    "f(x  + ϵ_x, y  + ϵ_y) = f(x,y) + f_x(x,y) ϵ_x + f_y(x,y) ϵ_y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**\n",
    "Complete the following implementation of `Dual2D` supporting `+` and `*` (and\n",
    "assuming `a,b,c` are `Float64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: *, +, ^\n",
    "struct Dual2D\n",
    "    a::Float64\n",
    "    b::Float64\n",
    "    c::Float64\n",
    "end\n",
    "\n",
    "\n",
    "function +(s::Dual2D, t::Dual2D)\n",
    "    # TODO: Implement +, returning a Dual2D\n",
    "    # SOLUTION\n",
    "    Dual2D(s.a + t.a, s.b + t.b, s.c + t.c)\n",
    "    # END\n",
    "end\n",
    "\n",
    "function *(c::Number, s::Dual2D)\n",
    "    # TODO: Implement c * Dual2D(...), returning a Dual2D\n",
    "    # SOLUTION\n",
    "    Dual2D(c * s.a, c * s.b, c * s.c)\n",
    "    # END\n",
    "end\n",
    "\n",
    "function *(s::Dual2D, t::Dual2D)\n",
    "    # TODO: Implement Dual2D(...) * Dual2D(...), returning a Dual2D\n",
    "\n",
    "    # SOLUTION\n",
    "    # we deduce (s.a + s.b ϵ_x + s.c ϵ_y)*(t.a + t.b ϵ_x + t.c ϵ_y) ==\n",
    "    # s.a * t.a + (s.a*t.b + s.b*t.a)*ϵ_x + (s.a*t.c + s.c*t.a)*ϵ_y\n",
    "    Dual2D(s.a * t.a, s.a * t.b + s.b * t.a, s.a * t.c + s.c * t.a)\n",
    "    # END\n",
    "end\n",
    "\n",
    "f = function (x, y) # (x+2y^2)^3 using only * and +\n",
    "    z = (x + 2y * y)\n",
    "    z * z * z\n",
    "end\n",
    "\n",
    "x,y = 1., 2.\n",
    "@test f(Dual2D(x,1.,0.), Dual2D(y,0.,1.)) == Dual2D(f(x,y), 3(x+2y^2)^2, 12y*(x+2y^2)^2)\n",
    "\n",
    "# This has computed the gradient as f(x,y) + f_x*ϵ_x + f_y*ϵ_y\n",
    "# == (x+2y^2)^3 + 3(x+2y^2)^2*ϵ_x + 12y(x+2y^2)^2*ϵ_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ForwardDiff.jl and computing derivatives/gradients/Jacobians/Hessians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ForwardDiff.jl is a package that uses dual numbers under the hood for automatic differentiation,\n",
    "including supporting gradients and Jacobians. Its usage in 1D works as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using ForwardDiff, Test\n",
    "\n",
    "@test ForwardDiff.derivative(cos, 0.1) ≈ -sin(0.1) # uses dual number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also works with higher dimensions,  allowing for arbitrary dimensional computation\n",
    "of gradients. Consider a simple function $f : ℝ^n → ℝ$ defined by\n",
    "$$\n",
    "f([x_1,…,x_n]) = ∑_{k=1}^{n-1} x_k x_{k+1}\n",
    "$$\n",
    "which we can implement as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#55 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = function(x)\n",
    "    ret = zero(eltype(x)) # Need to use zero(eltype(x)) to support dual numbers\n",
    "    for k = 1:length(x)-1\n",
    "        ret += x[k]*x[k+1]\n",
    "    end\n",
    "    ret\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ForwardDiff.jl to compute its gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -0.051329443945911546\n",
       "  0.7645780920005752\n",
       "  0.3874537814059064\n",
       "  0.07240474399473124\n",
       "  0.43878322535181796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = randn(5)\n",
    "ForwardDiff.gradient(f,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one catch is the complexity is quadratic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.142102 seconds (633.70 k allocations: 43.899 MiB, 3.23% gc time, 99.46% compilation time)\n",
      "  0.071308 seconds (8 allocations: 1.147 MiB, 5.34% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time ForwardDiff.gradient(f,randn(1000));\n",
    "@time ForwardDiff.gradient(f,randn(10_000)); # around 100x slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for this is if we have $n$ unknowns the higher-dimensional dual number uses $n$ different $ϵ$s\n",
    "for each argument, meaning the input has $n^2$ degrees-of-freedom.\n",
    "This will motivate the move to reverse-mode automatic differentiation in the next lab which will reduce the\n",
    "complexity to $O(n)$ for many gradient calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobians\n",
    "\n",
    "ForwardDiff.jl also works well with Jacobians, a problem where the benefits of reverse-mode automatic differentiation\n",
    "are less clear.\n",
    "Denote the Jacobian as\n",
    "$$\n",
    " J_f = \\begin{bmatrix} {∂ f_1 \\over ∂x_1} & ⋯ & {∂ f_1 \\over ∂x_ℓ} \\\\\n",
    "      ⋮ & ⋱ & ⋮ \\\\\n",
    "      {∂ f_m \\over ∂x_1} & ⋯ & {∂ f_m \\over ∂x_ℓ}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The function `ForwardDiff.jacobian(f, 𝐱)` computes $J_f(𝐱)$.\n",
    "Here is an example of computing the Jacobian of a simple function $f : ℝ^2 → ℝ^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = function(𝐱)\n",
    "    (x,y) = 𝐱 # get out the components of the vector\n",
    "    [exp(x*cos(y)), sin(exp(x*y))]\n",
    "end\n",
    "\n",
    "x,y = 0.1,0.2\n",
    "@test ForwardDiff.jacobian(f, [x,y]) ≈ [exp(x*cos(y))*cos(y)        -exp(x*cos(y))*x*sin(y);\n",
    "                                        cos(exp(x*y))*exp(x*y)*y     cos(exp(x*y))*exp(x*y)*x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4** We can also use ForwardDiff.jl to compute hessians via `ForwardDiff.hessian`. Compute the Hessian of the following Toda Hamiltonian\n",
    "$$\n",
    "  f([x_1, …, x_n, y_1, …, y_n]) =  {1 \\over 2} ∑_{k=1}^n y_k^2 + ∑_{k=1}^{n-1} \\exp(x_k - x_{k+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Matrix{Float64}:\n",
       "  0.367879  -0.367879   0.0       0.0  0.0  0.0\n",
       " -0.367879   0.735759  -0.367879  0.0  0.0  0.0\n",
       "  0.0       -0.367879   0.367879  0.0  0.0  0.0\n",
       "  0.0        0.0        0.0       1.0  0.0  0.0\n",
       "  0.0        0.0        0.0       0.0  1.0  0.0\n",
       "  0.0        0.0        0.0       0.0  0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function todahamiltonian(𝐱𝐲)\n",
    "    n = length(𝐱𝐲) ÷ 2\n",
    "    x,y = 𝐱𝐲[1:n], 𝐱𝐲[n+1:end] # split the input vector into its two components.\n",
    "    ret = zero(eltype(𝐱𝐲))\n",
    "    # TODO: implement the Hamiltonian, eg using for-loops\n",
    "    # SOLUTION\n",
    "    for k = 1:n\n",
    "        ret += y[k]^2/2\n",
    "    end\n",
    "    for k = 1:n-1\n",
    "        ret += exp(x[k] - x[k+1])\n",
    "    end\n",
    "    ret\n",
    "    # END\n",
    "end\n",
    "\n",
    "x = [1.,2,3]\n",
    "y = [4.,5,6]\n",
    "\n",
    "ForwardDiff.hessian(todahamiltonian, [x; y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will conclude with an application of these results to Newton's method.\n",
    "Given an initial guess $x_0$ to a root of a function $f$,  Newton's method is a simple sequence defined by\n",
    "$$\n",
    "x_{k+1} = x_k - {f(x_k) \\over f'(x_k)}\n",
    "$$\n",
    "If the initial guess $x_0$ is \"close enough\" to a root $r$ of $f$ (ie $f(r) = 0$)\n",
    "then it is known that $x_k → r$. Thus for large $N$ we have $x_N ≈ r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual numbers as implemented by `Dual` gives us a powerful tool to compute derivatives and get a simple implementation\n",
    "of Newton's method working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.193859111321223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# derivative(f, x) computes the derivative at a point x using our version of Dual\n",
    "derivative(f, x) = f(Dual(x,1)).b\n",
    "\n",
    "function newton(f, x, N) # x = x_0 is the initial guess\n",
    "    for k = 1:N\n",
    "        x = x - f(x)/derivative(f,x)\n",
    "    end\n",
    "    x\n",
    "end\n",
    "\n",
    "f = x -> x^5 + x^2 + 1\n",
    "r = newton(f, 0.1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test that we have indeed found a root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.661338147750939e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5(a)** Use `newton` with a complex number to compute\n",
    "an approximation to a complex root of $f(x) = x^5 - x^2 + 1$.\n",
    "Verify the approximation is accurate by testing that it satisfies $f(r)$\n",
    "is approximately zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16 + 0.0im"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: By making the initial guess complex find a complex root.\n",
    "# SOLUTION\n",
    "r = newton(f, 0.1 + 0.2im, 100)\n",
    "f(r) # close to zero\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5(b)** By changing the initial guesses compute 5 roots to\n",
    "$sin(x) - 1/x$. Hint: you may need to add an overload for `/(x::Real, y::Dual)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1141571408719302, -1.1141571408719302, 2.772604708265991, 9.31724294141481, 6.439117238417246)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use `newton` to compute roots of `sin(x) - 1/x`.\n",
    "# SOLUTION\n",
    "\n",
    "# We need to add a missing overload for `Dual`:\n",
    "\n",
    "/(x::Real, y::Dual) = Dual(x)/y\n",
    "\n",
    "\n",
    "# Changing the initial guess we get 5 distinct roots\n",
    "newton(x -> sin(x) - 1/x, 1, 100),\n",
    "newton(x -> sin(x) - 1/x, 2, 100),\n",
    "newton(x -> sin(x) - 1/x, 3, 100),\n",
    "newton(x -> sin(x) - 1/x, 5, 100),\n",
    "newton(x -> sin(x) - 1/x, 6, 100)\n",
    "\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6** Newton's method works also for finding roots of functions $f : ℝ^n → ℝ^n$ using the Jacobian.\n",
    "Extend our newton method for vector-valued functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function newton(f, x::AbstractVector, N) # x = x_0 is the inital guess, now a vector\n",
    "    # TODO: reimplement newton for vector inputs using ForwardDiff.jacobian\n",
    "    # SOLUTION\n",
    "    for k = 1:N\n",
    "        x = x - ForwardDiff.jacobian(f,x) \\ f(x)\n",
    "    end\n",
    "    x\n",
    "    # END\n",
    "end\n",
    "\n",
    "f = function(𝐱)\n",
    "    (x,y) = 𝐱 # get out the components of the vector\n",
    "    [cos(7x^2*y + y), cos(7*x*y)]\n",
    "end\n",
    "\n",
    "@test maximum(abs,f(newton(f, [0.1,0.2], 200))) ≤ 1E-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
